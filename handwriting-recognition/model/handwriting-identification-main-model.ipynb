{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:08:46.509769Z",
     "iopub.status.busy": "2024-12-04T20:08:46.509035Z",
     "iopub.status.idle": "2024-12-04T20:08:46.514356Z",
     "shell.execute_reply": "2024-12-04T20:08:46.513403Z",
     "shell.execute_reply.started": "2024-12-04T20:08:46.509737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from simple_cnn import SimpleCNN\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations: Resize, Normalize\n",
    "transform_main_model = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to fixed size\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset base (senza transform) ---\n",
    "dataset = ImageFolder(root='../../IAM+RIMES')  # nessuna transform qui\n",
    "\n",
    "# --- Carica lo split ---\n",
    "#split = torch.load('splits/dataset_split.pth')\n",
    "#train_indices = split['train_indices']\n",
    "#val_indices = split['val_indices']\n",
    "split = torch.load('splits/IAM+RIMES.pth')\n",
    "\n",
    "train_indices = split['train_indices']\n",
    "test_indices = split['test_indices']\n",
    "label_map = split['label_map']\n",
    "\n",
    "print(f\"Numero train samples: {len(train_indices)}\")\n",
    "print(f\"Numero test samples: {len(test_indices)}\")\n",
    "print(f\"Numero classi (label ricodificati): {len(label_map)}\")\n",
    "\n",
    "# --- Applica lo split ---\n",
    "train_subset = Subset(dataset, train_indices)\n",
    "val_subset = Subset(dataset, test_indices)\n",
    "\n",
    "class TransformedSubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform, label_map):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map  # dizionario {label_originale: label_ricodificato}\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.subset[idx]\n",
    "        if label in self.label_map:\n",
    "            mapped_label = self.label_map[label]\n",
    "        else:\n",
    "            # Label non autorizzata, assegna -1 o altra label \"speciale\"\n",
    "            mapped_label = -1\n",
    "        return self.transform(img), mapped_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "# --- Applica le trasformazioni specifiche ---\n",
    "train_data = TransformedSubset(train_subset, transform_main_model, label_map)\n",
    "\n",
    "# --- Calcola il numero di classi a partire dal training set ---\n",
    "all_labels = [label for _, label in train_subset]\n",
    "\n",
    "num_classes = len(label_map)\n",
    "print(f\"Numero di classi (utenti autorizzati): {num_classes}\")\n",
    "\n",
    "val_data = TransformedSubset(val_subset, transform_main_model, label_map)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:11:23.899627Z",
     "iopub.status.busy": "2024-12-04T20:11:23.898911Z",
     "iopub.status.idle": "2024-12-04T20:11:24.930132Z",
     "shell.execute_reply": "2024-12-04T20:11:24.929371Z",
     "shell.execute_reply.started": "2024-12-04T20:11:23.899596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:14:10.060327Z",
     "iopub.status.busy": "2024-12-04T20:14:10.059666Z",
     "iopub.status.idle": "2024-12-04T20:14:10.064758Z",
     "shell.execute_reply": "2024-12-04T20:14:10.063887Z",
     "shell.execute_reply.started": "2024-12-04T20:14:10.060293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 25\n",
    "threshold = 0.6  # soglia di confidenza per accettare la predizione\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_auth_accuracies = []\n",
    "val_far_rates = []\n",
    "val_frr_rates = []\n",
    "val_overall_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics on train batch\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct_train / total_train)\n",
    "\n",
    "    # Validation estesa con soglia\n",
    "    model.eval()\n",
    "    correct_auth = 0\n",
    "    total_auth = 0\n",
    "    false_accepts = 0\n",
    "    false_rejects = 0\n",
    "    total_unauth = 0\n",
    "    total_test = 0\n",
    "    correct_total = 0\n",
    "    confidence_sum = 0.0\n",
    "    confidence_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            max_probs, predicted = torch.max(probs, 1)\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                conf = max_probs[i].item()\n",
    "\n",
    "                # Accumula confidenza per media\n",
    "                confidence_sum += conf\n",
    "                confidence_count += 1\n",
    "\n",
    "                # Se confidenza sotto soglia => consideriamo \"non autorizzato\" (-1)\n",
    "                if conf < threshold:\n",
    "                    pred = -1\n",
    "\n",
    "                if label == -1:  # Utente non autorizzato\n",
    "                    total_unauth += 1\n",
    "                    if pred != -1:  # falso accetto\n",
    "                        false_accepts += 1\n",
    "                else:  # Utente autorizzato\n",
    "                    total_auth += 1\n",
    "                    if pred == label:\n",
    "                        correct_auth += 1\n",
    "                    else:\n",
    "                        false_rejects += 1\n",
    "\n",
    "                # Accuratezza globale\n",
    "                if (label != -1 and pred == label) or (label == -1 and pred == -1):\n",
    "                    correct_total += 1\n",
    "                total_test += 1\n",
    "\n",
    "    auth_acc = 100 * correct_auth / total_auth if total_auth > 0 else 0\n",
    "    far = 100 * false_accepts / total_unauth if total_unauth > 0 else 0\n",
    "    frr = 100 * false_rejects / total_auth if total_auth > 0 else 0\n",
    "    overall_acc = 100 * correct_total / total_test if total_test > 0 else 0\n",
    "    # Calcola confidenza media\n",
    "    avg_confidence = confidence_sum / confidence_count if confidence_count > 0 else 0.0\n",
    "\n",
    "    val_auth_accuracies.append(auth_acc)\n",
    "    val_far_rates.append(far)\n",
    "    val_frr_rates.append(frr)\n",
    "    val_overall_accuracies.append(overall_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"total_auth: {total_auth}\")\n",
    "    print(f\"total_unauth: {total_unauth}\")\n",
    "    print(f\"  Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    print(f\"  Train Accuracy: {train_accuracies[-1]:.2f}%\")\n",
    "    print(f\"  Validation Auth Accuracy: {auth_acc:.2f}%\")\n",
    "    print(f\"  Validation FAR (False Accept Rate): {far:.2f}%\")\n",
    "    print(f\"  Validation FRR (False Reject Rate): {frr:.2f}%\")\n",
    "    print(f\"  Validation Overall Accuracy: {overall_acc:.2f}%\")\n",
    "    print(f\"  AVG Confidence: {avg_confidence:.2f}%\")\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'base_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1094263,
     "sourceId": 1840441,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "bio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
