{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdfee880",
   "metadata": {},
   "source": [
    "Split the dataset into training and test set for fair comparison between the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a7a00",
   "metadata": {},
   "source": [
    "IAM+RIMES split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db34d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Percorso merged dataset\n",
    "# -----------------------------\n",
    "data_dir = '../../IAM+RIMES'  # IAM + RIMES già uniti\n",
    "\n",
    "# Trasformazioni immagini\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Parametri\n",
    "max_authorized = 200\n",
    "max_unauthorized = 50\n",
    "\n",
    "# Carica dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Conta campioni per writer\n",
    "writer_to_indices = defaultdict(list)\n",
    "for idx, sample in enumerate(dataset):\n",
    "    writer_to_indices[sample[1]].append(idx)\n",
    "\n",
    "# -----------------------------\n",
    "#Escludi writer \"000\" (IAM)\n",
    "# -----------------------------\n",
    "# Trova il label index associato a \"000\" (se presente)\n",
    "writer_name_to_idx = dataset.class_to_idx  # mappa {nome_cartella: indice}\n",
    "if \"000\" in writer_name_to_idx:\n",
    "    idx_000 = writer_name_to_idx[\"000\"]\n",
    "    if idx_000 in writer_to_indices:\n",
    "        del writer_to_indices[idx_000]\n",
    "    print(\"Writer '000' escluso dal dataset\")\n",
    "\n",
    "# Filtra autori con almeno 2 campioni\n",
    "filtered_writer_to_indices = {w: idxs for w, idxs in writer_to_indices.items() if len(idxs) >= 2}\n",
    "\n",
    "# Classifica gli autori per numero di campioni (discendente)\n",
    "sorted_writers = sorted(filtered_writer_to_indices.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "# Identifica se writer è IAM o RIMES\n",
    "def writer_source(writer_id):\n",
    "    # supponiamo che IAM abbia id numerici, RIMES id stringhe → adatta se serve\n",
    "    return \"IAM\" if str(writer_id).isdigit() else \"RIMES\"\n",
    "\n",
    "iam_writers = [w for w, idxs in sorted_writers if writer_source(w) == \"IAM\"]\n",
    "rimes_writers = [w for w, idxs in sorted_writers if writer_source(w) == \"RIMES\"]\n",
    "\n",
    "# Seleziona bilanciato IAM+RIMES\n",
    "n_iam = max_authorized // 2\n",
    "n_rimes = max_authorized - n_iam\n",
    "authorized_writers = set(iam_writers[:n_iam] + rimes_writers[:n_rimes])\n",
    "\n",
    "# Gli altri diventano non autorizzati\n",
    "unauthorized_writers = set(w for w, _ in sorted_writers if w not in authorized_writers)\n",
    "if len(unauthorized_writers) > max_unauthorized:\n",
    "    unauthorized_writers = set(random.sample(list(unauthorized_writers), max_unauthorized))\n",
    "\n",
    "# -----------------------------\n",
    "# Creazione train/test indices\n",
    "# -----------------------------\n",
    "train_indices, test_auth_samples, test_unauth_samples = [], [], []\n",
    "\n",
    "# Autorizzati: n-1 campioni train, 1 test\n",
    "for writer in authorized_writers:\n",
    "    indices = filtered_writer_to_indices[writer]\n",
    "    random.shuffle(indices)\n",
    "    train_indices.extend(indices[:-1])  # tutti tranne 1\n",
    "    test_auth_samples.append(indices[-1])  # ultimo per test\n",
    "\n",
    "# Non autorizzati: 1 campione per writer nel test\n",
    "for writer in unauthorized_writers:\n",
    "    indices = filtered_writer_to_indices[writer]\n",
    "    sample = random.choice(indices)\n",
    "    test_unauth_samples.append(sample)\n",
    "\n",
    "# Combina test set\n",
    "test_indices = test_auth_samples + test_unauth_samples\n",
    "random.shuffle(test_indices)\n",
    "\n",
    "print(f\"Train set: {len(train_indices)} campioni (solo autorizzati)\")\n",
    "print(f\"Test set: {len(test_indices)} campioni (autorizzati + non)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Statistiche\n",
    "# -----------------------------\n",
    "train_writer_ids = [dataset[idx][1] for idx in train_indices]\n",
    "test_writer_ids = [dataset[idx][1] for idx in test_indices]\n",
    "\n",
    "test_auth_ids = [i for i in test_writer_ids if i in authorized_writers]\n",
    "test_unauth_ids = [i for i in test_writer_ids if i in unauthorized_writers]\n",
    "\n",
    "train_count = Counter(train_writer_ids)\n",
    "test_auth_count = Counter(test_auth_ids)\n",
    "test_unauth_count = Counter(test_unauth_ids)\n",
    "\n",
    "print(\"Statistiche principali\")\n",
    "print(f\"- Utenti autorizzati: {len(authorized_writers)}\")\n",
    "print(f\"  ↳ Campioni nel train set: {len(train_indices)}\")\n",
    "print(f\"  ↳ Campioni autorizzati nel test set: {sum(test_auth_count.values())}\")\n",
    "print(f\"- Utenti non autorizzati: {len(unauthorized_writers)}\")\n",
    "print(f\"  ↳ Campioni non autorizzati nel test set: {sum(test_unauth_count.values())}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Salvataggio split\n",
    "# -----------------------------\n",
    "label_map = {orig: i for i, orig in enumerate(sorted(authorized_writers))}  # solo autorizzati\n",
    "split = {\n",
    "    'train_indices': train_indices,\n",
    "    'test_indices': test_indices,\n",
    "    'label_map': label_map\n",
    "}\n",
    "os.makedirs('splits', exist_ok=True)\n",
    "torch.save(split, 'splits/merged_dataset_split_improved.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8faef",
   "metadata": {},
   "source": [
    "Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6897fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "root = '../merged_dataset'\n",
    "\n",
    "sizes = Counter()\n",
    "by_writer_count = Counter()\n",
    "unknown_count = 0\n",
    "sample_dim = defaultdict(list)\n",
    "\n",
    "for writer in os.listdir(root):\n",
    "    wdir = os.path.join(root, writer)\n",
    "    if not os.path.isdir(wdir): \n",
    "        continue\n",
    "    files = [f for f in os.listdir(wdir) if f.lower().endswith(('.png','.jpg','.jpeg','.tif','.tiff'))]\n",
    "    by_writer_count[writer] += len(files)\n",
    "    if 'unknown' in writer.lower():\n",
    "        unknown_count += len(files)\n",
    "    # campiona poche immagini per writer\n",
    "    for f in files[:3]:\n",
    "        p = os.path.join(wdir,f)\n",
    "        try:\n",
    "            with Image.open(p) as im:\n",
    "                sizes[(im.width, im.height)] += 1\n",
    "                sample_dim[writer].append((im.width, im.height))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print('Top 10 dimensioni:', sizes.most_common(10))\n",
    "print('Writer totali:', len(by_writer_count))\n",
    "print('Immagini totali:', sum(by_writer_count.values()))\n",
    "print('Immagini in classi *_unknown:', unknown_count)\n",
    "big = sum(1 for wh,c in sizes.items() if max(wh) > 1000)\n",
    "print('Numero di formati “grandi” (max side > 1000):', big)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"../../IAM+RIMES\"\n",
    "\n",
    "# 1. Conta le sottocartelle (writer)\n",
    "all_writers = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "print(f\"Numero totale di writer (sottocartelle): {len(all_writers)}\")\n",
    "\n",
    "# 2. Conta immagini per ciascun writer\n",
    "writer_image_counts = {}\n",
    "for writer in all_writers:\n",
    "    writer_path = os.path.join(data_dir, writer)\n",
    "    n_images = len([f for f in os.listdir(writer_path) if os.path.isfile(os.path.join(writer_path, f))])\n",
    "    writer_image_counts[writer] = n_images\n",
    "\n",
    "# 3. Statistiche generali\n",
    "writers_with_3plus = [w for w, n in writer_image_counts.items() if n >= 3]\n",
    "print(f\"Writer con almeno 3 immagini: {len(writers_with_3plus)}\")\n",
    "print(f\"Writer con meno di 3 immagini: {len(all_writers) - len(writers_with_3plus)}\")\n",
    "\n",
    "# 4. (Opzionale) Mostra i primi 20 writer con numero di immagini\n",
    "print(\"\\nEsempio primi 20 writer e numero di immagini:\")\n",
    "for w in list(writer_image_counts.keys())[:20]:\n",
    "    print(f\"{w}: {writer_image_counts[w]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"../../merged_dataset\"\n",
    "\n",
    "writers = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "\n",
    "writers_with_3_or_more = [\n",
    "    w for w in writers if len(os.listdir(os.path.join(data_dir, w))) >= 4\n",
    "]\n",
    "\n",
    "print(f\"Numero totale writer: {len(writers)}\")\n",
    "print(f\"Numero writer con almeno 3 campioni: {len(writers_with_3_or_more)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
