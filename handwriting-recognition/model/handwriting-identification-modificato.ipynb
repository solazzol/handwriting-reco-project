{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:08:46.509769Z",
     "iopub.status.busy": "2024-12-04T20:08:46.509035Z",
     "iopub.status.idle": "2024-12-04T20:08:46.514356Z",
     "shell.execute_reply": "2024-12-04T20:08:46.513403Z",
     "shell.execute_reply.started": "2024-12-04T20:08:46.509737Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from simple_cnn import SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations: Resize, Normalize\n",
    "transform_main_model = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to fixed size\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset base (senza transform) ---\n",
    "dataset = ImageFolder(root='data')  # nessuna transform qui\n",
    "\n",
    "# --- Carica lo split ---\n",
    "split = torch.load('splits/dataset_split.pth')\n",
    "train_indices = split['train_indices']\n",
    "val_indices = split['val_indices']\n",
    "\n",
    "# --- Applica lo split ---\n",
    "train_subset = Subset(dataset, train_indices)\n",
    "val_subset = Subset(dataset, val_indices)\n",
    "\n",
    "# --- Wrapper per applicare transform dinamicamente ---\n",
    "class TransformedSubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.subset[idx]\n",
    "        return self.transform(img), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "# --- Applica le trasformazioni specifiche ---\n",
    "train_data = TransformedSubset(train_subset, transform_main_model)\n",
    "\n",
    "# --- Calcola il numero di classi a partire dal training set ---\n",
    "all_labels = [label for _, label in train_subset]\n",
    "num_classes = len(set(all_labels))\n",
    "\n",
    "print(f\"Numero di classi (utenti autorizzati): {num_classes}\")\n",
    "\n",
    "val_data = TransformedSubset(val_subset, transform_main_model)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:11:23.899627Z",
     "iopub.status.busy": "2024-12-04T20:11:23.898911Z",
     "iopub.status.idle": "2024-12-04T20:11:24.930132Z",
     "shell.execute_reply": "2024-12-04T20:11:24.929371Z",
     "shell.execute_reply.started": "2024-12-04T20:11:23.899596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:14:10.060327Z",
     "iopub.status.busy": "2024-12-04T20:14:10.059666Z",
     "iopub.status.idle": "2024-12-04T20:14:10.064758Z",
     "shell.execute_reply": "2024-12-04T20:14:10.063887Z",
     "shell.execute_reply.started": "2024-12-04T20:14:10.060293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:14:16.981234Z",
     "iopub.status.busy": "2024-12-04T20:14:16.980902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 6.5989, Train Accuracy: 4.71%, Validation Accuracy: 2.60%\n",
      "Epoch [2/25], Loss: 5.3329, Train Accuracy: 10.56%, Validation Accuracy: 5.52%\n",
      "Epoch [3/25], Loss: 4.3105, Train Accuracy: 18.68%, Validation Accuracy: 14.29%\n",
      "Epoch [4/25], Loss: 3.3496, Train Accuracy: 31.52%, Validation Accuracy: 20.78%\n",
      "Epoch [5/25], Loss: 2.4802, Train Accuracy: 44.92%, Validation Accuracy: 30.52%\n",
      "Epoch [6/25], Loss: 1.7467, Train Accuracy: 57.84%, Validation Accuracy: 39.29%\n",
      "Epoch [7/25], Loss: 1.2008, Train Accuracy: 71.08%, Validation Accuracy: 23.38%\n",
      "Epoch [8/25], Loss: 0.7626, Train Accuracy: 83.35%, Validation Accuracy: 47.08%\n",
      "Epoch [9/25], Loss: 0.5044, Train Accuracy: 89.68%, Validation Accuracy: 40.91%\n",
      "Epoch [10/25], Loss: 0.3462, Train Accuracy: 93.26%, Validation Accuracy: 28.57%\n",
      "Epoch [11/25], Loss: 0.2725, Train Accuracy: 94.72%, Validation Accuracy: 27.27%\n",
      "Epoch [12/25], Loss: 0.2063, Train Accuracy: 96.67%, Validation Accuracy: 45.45%\n",
      "Epoch [13/25], Loss: 0.1465, Train Accuracy: 97.32%, Validation Accuracy: 43.51%\n",
      "Epoch [14/25], Loss: 0.1251, Train Accuracy: 98.05%, Validation Accuracy: 20.45%\n",
      "Epoch [15/25], Loss: 0.1080, Train Accuracy: 97.97%, Validation Accuracy: 29.22%\n",
      "Epoch [16/25], Loss: 0.0953, Train Accuracy: 98.62%, Validation Accuracy: 52.27%\n",
      "Epoch [17/25], Loss: 0.0925, Train Accuracy: 98.29%, Validation Accuracy: 44.81%\n",
      "Epoch [18/25], Loss: 0.0956, Train Accuracy: 98.38%, Validation Accuracy: 50.32%\n",
      "Epoch [19/25], Loss: 0.0822, Train Accuracy: 98.21%, Validation Accuracy: 43.18%\n",
      "Epoch [20/25], Loss: 0.0966, Train Accuracy: 98.21%, Validation Accuracy: 46.75%\n",
      "Epoch [21/25], Loss: 0.0955, Train Accuracy: 97.97%, Validation Accuracy: 21.75%\n",
      "Epoch [22/25], Loss: 0.0738, Train Accuracy: 98.78%, Validation Accuracy: 21.10%\n",
      "Epoch [23/25], Loss: 0.0595, Train Accuracy: 99.27%, Validation Accuracy: 26.95%\n",
      "Epoch [24/25], Loss: 0.0423, Train Accuracy: 99.19%, Validation Accuracy: 42.86%\n",
      "Epoch [25/25], Loss: 0.0307, Train Accuracy: 99.68%, Validation Accuracy: 33.77%\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the Model\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct / total)\n",
    "\n",
    "    # Validation Accuracy\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "    val_accuracies.append(100 * correct_val / total_val)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracies[-1]:.2f}%, Validation Accuracy: {val_accuracies[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'handwriting_identification_main_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot Training and Validation Metrics\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy', linestyle='--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Inferenza con softmax per test e valutazione confidenza ---\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_confidences = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        confs, predicted = torch.max(probs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "        all_confidences.extend(confs.cpu().numpy())\n",
    "\n",
    "# Esempio: stampa prime 10 predizioni e confidenze\n",
    "for i in range(10):\n",
    "    print(f\"Target: {all_targets[i]}, Predicted: {all_preds[i]}, Confidenza: {all_confidences[i]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1094263,
     "sourceId": 1840441,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "bio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
